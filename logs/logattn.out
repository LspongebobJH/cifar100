nohup: ignoring input
Namespace(backbone='resnet50', ft_type='attn', epochs=200, batch_size=32, num_classes=100, warm=1, base=False, lr=0.1, device='cuda:2', num_workers=8, hid_dim=4, n_heads_list=[1])
Files already downloaded and verified
Files already downloaded and verified
Training Epoch: 1 [160/50000]	Loss: 7.8108	LR: 0.000000
Training Epoch: 1 [192/50000]	Loss: 8.9419	LR: 0.000064
Training Epoch: 1 [224/50000]	Loss: 9.3566	LR: 0.000128
Training Epoch: 1 [256/50000]	Loss: 10.3184	LR: 0.000192
Training Epoch: 1 [288/50000]	Loss: 6.8550	LR: 0.000256
Training Epoch: 1 [320/50000]	Loss: 6.7781	LR: 0.000320
Training Epoch: 1 [352/50000]	Loss: 10.7884	LR: 0.000384
Training Epoch: 1 [384/50000]	Loss: 6.8444	LR: 0.000448
Training Epoch: 1 [416/50000]	Loss: 7.1628	LR: 0.000512
Training Epoch: 1 [448/50000]	Loss: 6.3528	LR: 0.000576
Training Epoch: 1 [480/50000]	Loss: 5.1101	LR: 0.000640
Training Epoch: 1 [512/50000]	Loss: 5.7599	LR: 0.000704
Training Epoch: 1 [544/50000]	Loss: 5.7827	LR: 0.000768
Training Epoch: 1 [576/50000]	Loss: 10.1627	LR: 0.000832
Training Epoch: 1 [608/50000]	Loss: 5.1946	LR: 0.000896
Training Epoch: 1 [640/50000]	Loss: 10.4483	LR: 0.000960
Training Epoch: 1 [672/50000]	Loss: 7.7842	LR: 0.001024
Training Epoch: 1 [704/50000]	Loss: 4.7166	LR: 0.001088
Training Epoch: 1 [736/50000]	Loss: 7.8645	LR: 0.001152
Training Epoch: 1 [768/50000]	Loss: 6.6843	LR: 0.001216
Training Epoch: 1 [800/50000]	Loss: 9.3340	LR: 0.001280
Training Epoch: 1 [832/50000]	Loss: 4.7171	LR: 0.001344
Training Epoch: 1 [864/50000]	Loss: 4.9948	LR: 0.001408
Training Epoch: 1 [896/50000]	Loss: 5.0371	LR: 0.001472
Training Epoch: 1 [928/50000]	Loss: 14.9361	LR: 0.001536
Training Epoch: 1 [960/50000]	Loss: 6.6248	LR: 0.001599
Training Epoch: 1 [992/50000]	Loss: 8.6136	LR: 0.001663
Training Epoch: 1 [1024/50000]	Loss: 24.1612	LR: 0.001727
Training Epoch: 1 [1056/50000]	Loss: 4.9546	LR: 0.001791
Training Epoch: 1 [1088/50000]	Loss: 5.7087	LR: 0.001855
Training Epoch: 1 [1120/50000]	Loss: 4.9055	LR: 0.001919
Training Epoch: 1 [1152/50000]	Loss: 10.9210	LR: 0.001983
Training Epoch: 1 [1184/50000]	Loss: 5.0428	LR: 0.002047
Training Epoch: 1 [1216/50000]	Loss: 4.6579	LR: 0.002111
Training Epoch: 1 [1248/50000]	Loss: 6.8241	LR: 0.002175
Training Epoch: 1 [1280/50000]	Loss: 13.2258	LR: 0.002239
Training Epoch: 1 [1312/50000]	Loss: 4.9649	LR: 0.002303
Training Epoch: 1 [1344/50000]	Loss: 5.0630	LR: 0.002367
Training Epoch: 1 [1376/50000]	Loss: 4.6473	LR: 0.002431
Training Epoch: 1 [1408/50000]	Loss: 4.7834	LR: 0.002495
Training Epoch: 1 [1440/50000]	Loss: 4.5962	LR: 0.002559
Training Epoch: 1 [1472/50000]	Loss: 18.8229	LR: 0.002623
Training Epoch: 1 [1504/50000]	Loss: 14.8178	LR: 0.002687
Training Epoch: 1 [1536/50000]	Loss: 5.0144	LR: 0.002751
Training Epoch: 1 [1568/50000]	Loss: 7.4515	LR: 0.002815
Training Epoch: 1 [1600/50000]	Loss: 24.3951	LR: 0.002879
Training Epoch: 1 [1632/50000]	Loss: 6.2714	LR: 0.002943
Training Epoch: 1 [1664/50000]	Loss: 7.7945	LR: 0.003007
Training Epoch: 1 [1696/50000]	Loss: 11.5058	LR: 0.003071
Training Epoch: 1 [1728/50000]	Loss: 4.8630	LR: 0.003135
Training Epoch: 1 [1760/50000]	Loss: 4.8952	LR: 0.003199
Training Epoch: 1 [1792/50000]	Loss: 25.8120	LR: 0.003263
Training Epoch: 1 [1824/50000]	Loss: 19.0851	LR: 0.003327
Training Epoch: 1 [1856/50000]	Loss: 4.9073	LR: 0.003391
Training Epoch: 1 [1888/50000]	Loss: 20.6130	LR: 0.003455
Training Epoch: 1 [1920/50000]	Loss: 5.1265	LR: 0.003519
Training Epoch: 1 [1952/50000]	Loss: 5.9775	LR: 0.003583
Training Epoch: 1 [1984/50000]	Loss: 5.6386	LR: 0.003647
Training Epoch: 1 [2016/50000]	Loss: 4.8989	LR: 0.003711
Training Epoch: 1 [2048/50000]	Loss: 5.1427	LR: 0.003775
Training Epoch: 1 [2080/50000]	Loss: 9.2678	LR: 0.003839
Training Epoch: 1 [2112/50000]	Loss: 4.6573	LR: 0.003903
Training Epoch: 1 [2144/50000]	Loss: 8.5707	LR: 0.003967
Training Epoch: 1 [2176/50000]	Loss: 22.8805	LR: 0.004031
Training Epoch: 1 [2208/50000]	Loss: 6.6684	LR: 0.004095
Training Epoch: 1 [2240/50000]	Loss: 14.2048	LR: 0.004159
Training Epoch: 1 [2272/50000]	Loss: 7.9109	LR: 0.004223
Training Epoch: 1 [2304/50000]	Loss: 11.9381	LR: 0.004287
Training Epoch: 1 [2336/50000]	Loss: 4.9144	LR: 0.004351
Training Epoch: 1 [2368/50000]	Loss: 9.6892	LR: 0.004415
Training Epoch: 1 [2400/50000]	Loss: 14.5700	LR: 0.004479
Training Epoch: 1 [2432/50000]	Loss: 12.2944	LR: 0.004543
Training Epoch: 1 [2464/50000]	Loss: 7.8330	LR: 0.004607
Training Epoch: 1 [2496/50000]	Loss: 4.6850	LR: 0.004671
Training Epoch: 1 [2528/50000]	Loss: 4.8719	LR: 0.004734
Training Epoch: 1 [2560/50000]	Loss: 4.8307	LR: 0.004798
Training Epoch: 1 [2592/50000]	Loss: 5.5495	LR: 0.004862
Training Epoch: 1 [2624/50000]	Loss: 4.9986	LR: 0.004926
Training Epoch: 1 [2656/50000]	Loss: 15.2604	LR: 0.004990
Training Epoch: 1 [2688/50000]	Loss: 5.5645	LR: 0.005054
Training Epoch: 1 [2720/50000]	Loss: 5.9250	LR: 0.005118
Training Epoch: 1 [2752/50000]	Loss: 5.0801	LR: 0.005182
Training Epoch: 1 [2784/50000]	Loss: 4.9213	LR: 0.005246
Training Epoch: 1 [2816/50000]	Loss: 6.2269	LR: 0.005310
Training Epoch: 1 [2848/50000]	Loss: 5.7531	LR: 0.005374
Training Epoch: 1 [2880/50000]	Loss: 34.3261	LR: 0.005438
Training Epoch: 1 [2912/50000]	Loss: 12.7583	LR: 0.005502
Training Epoch: 1 [2944/50000]	Loss: 6.6617	LR: 0.005566
Training Epoch: 1 [2976/50000]	Loss: 5.7070	LR: 0.005630
Training Epoch: 1 [3008/50000]	Loss: 5.7542	LR: 0.005694
Training Epoch: 1 [3040/50000]	Loss: 4.7621	LR: 0.005758
Training Epoch: 1 [3072/50000]	Loss: 6.0704	LR: 0.005822
Training Epoch: 1 [3104/50000]	Loss: 5.8653	LR: 0.005886
Training Epoch: 1 [3136/50000]	Loss: 4.8408	LR: 0.005950
Training Epoch: 1 [3168/50000]	Loss: 12.6582	LR: 0.006014
Training Epoch: 1 [3200/50000]	Loss: 5.0165	LR: 0.006078
Training Epoch: 1 [3232/50000]	Loss: 5.9109	LR: 0.006142
Training Epoch: 1 [3264/50000]	Loss: 5.9771	LR: 0.006206
Training Epoch: 1 [3296/50000]	Loss: 5.3947	LR: 0.006270
Training Epoch: 1 [3328/50000]	Loss: 7.2923	LR: 0.006334
Training Epoch: 1 [3360/50000]	Loss: 4.7727	LR: 0.006398
Training Epoch: 1 [3392/50000]	Loss: 5.9475	LR: 0.006462
Training Epoch: 1 [3424/50000]	Loss: 5.3772	LR: 0.006526
Training Epoch: 1 [3456/50000]	Loss: 12.3449	LR: 0.006590
Training Epoch: 1 [3488/50000]	Loss: 7.3520	LR: 0.006654
Training Epoch: 1 [3520/50000]	Loss: 8.7363	LR: 0.006718
Training Epoch: 1 [3552/50000]	Loss: 5.6394	LR: 0.006782
Training Epoch: 1 [3584/50000]	Loss: 9.5362	LR: 0.006846
Training Epoch: 1 [3616/50000]	Loss: 6.0990	LR: 0.006910
Training Epoch: 1 [3648/50000]	Loss: 5.8887	LR: 0.006974
Training Epoch: 1 [3680/50000]	Loss: 5.0968	LR: 0.007038
Training Epoch: 1 [3712/50000]	Loss: 4.7317	LR: 0.007102
Training Epoch: 1 [3744/50000]	Loss: 7.0615	LR: 0.007166
Training Epoch: 1 [3776/50000]	Loss: 6.0125	LR: 0.007230
Training Epoch: 1 [3808/50000]	Loss: 4.8110	LR: 0.007294
Training Epoch: 1 [3840/50000]	Loss: 4.9337	LR: 0.007358
Training Epoch: 1 [3872/50000]	Loss: 4.8137	LR: 0.007422
Training Epoch: 1 [3904/50000]	Loss: 4.8437	LR: 0.007486
Training Epoch: 1 [3936/50000]	Loss: 5.1617	LR: 0.007550
Training Epoch: 1 [3968/50000]	Loss: 4.9799	LR: 0.007614
Training Epoch: 1 [4000/50000]	Loss: 5.2982	LR: 0.007678
Training Epoch: 1 [4032/50000]	Loss: 5.0952	LR: 0.007742
Training Epoch: 1 [4064/50000]	Loss: 7.9752	LR: 0.007806
Training Epoch: 1 [4096/50000]	Loss: 4.7106	LR: 0.007869
Training Epoch: 1 [4128/50000]	Loss: 5.6050	LR: 0.007933
Training Epoch: 1 [4160/50000]	Loss: 5.5987	LR: 0.007997
Training Epoch: 1 [4192/50000]	Loss: 5.2992	LR: 0.008061
Training Epoch: 1 [4224/50000]	Loss: 4.9914	LR: 0.008125
Training Epoch: 1 [4256/50000]	Loss: 6.2804	LR: 0.008189
Training Epoch: 1 [4288/50000]	Loss: 4.9948	LR: 0.008253
Training Epoch: 1 [4320/50000]	Loss: 5.2793	LR: 0.008317
Training Epoch: 1 [4352/50000]	Loss: 5.1510	LR: 0.008381
Training Epoch: 1 [4384/50000]	Loss: 5.2093	LR: 0.008445
Training Epoch: 1 [4416/50000]	Loss: 4.9858	LR: 0.008509
Training Epoch: 1 [4448/50000]	Loss: 5.2211	LR: 0.008573
Training Epoch: 1 [4480/50000]	Loss: 4.6183	LR: 0.008637
Training Epoch: 1 [4512/50000]	Loss: 9.2279	LR: 0.008701
Training Epoch: 1 [4544/50000]	Loss: 4.8802	LR: 0.008765
Training Epoch: 1 [4576/50000]	Loss: 5.0281	LR: 0.008829
Training Epoch: 1 [4608/50000]	Loss: 5.5548	LR: 0.008893
Training Epoch: 1 [4640/50000]	Loss: 4.8761	LR: 0.008957
Training Epoch: 1 [4672/50000]	Loss: 4.7156	LR: 0.009021
Training Epoch: 1 [4704/50000]	Loss: 5.0278	LR: 0.009085
Training Epoch: 1 [4736/50000]	Loss: 4.7004	LR: 0.009149
Training Epoch: 1 [4768/50000]	Loss: 4.9489	LR: 0.009213
Training Epoch: 1 [4800/50000]	Loss: 5.0740	LR: 0.009277
Training Epoch: 1 [4832/50000]	Loss: 4.9872	LR: 0.009341
Training Epoch: 1 [4864/50000]	Loss: 5.0539	LR: 0.009405
Training Epoch: 1 [4896/50000]	Loss: 4.7875	LR: 0.009469
Training Epoch: 1 [4928/50000]	Loss: 4.7843	LR: 0.009533
Training Epoch: 1 [4960/50000]	Loss: 4.8482	LR: 0.009597
Training Epoch: 1 [4992/50000]	Loss: 5.0496	LR: 0.009661
Training Epoch: 1 [5024/50000]	Loss: 5.4242	LR: 0.009725
Training Epoch: 1 [5056/50000]	Loss: 5.2655	LR: 0.009789
Training Epoch: 1 [5088/50000]	Loss: 4.9208	LR: 0.009853
Training Epoch: 1 [5120/50000]	Loss: 5.2077	LR: 0.009917
Training Epoch: 1 [5152/50000]	Loss: 4.7912	LR: 0.009981
Training Epoch: 1 [5184/50000]	Loss: 5.0736	LR: 0.010045
Training Epoch: 1 [5216/50000]	Loss: 4.8188	LR: 0.010109
Training Epoch: 1 [5248/50000]	Loss: 13.9043	LR: 0.010173
Training Epoch: 1 [5280/50000]	Loss: 5.1694	LR: 0.010237
Training Epoch: 1 [5312/50000]	Loss: 4.6661	LR: 0.010301
Training Epoch: 1 [5344/50000]	Loss: 5.1179	LR: 0.010365
Training Epoch: 1 [5376/50000]	Loss: 4.4767	LR: 0.010429
Training Epoch: 1 [5408/50000]	Loss: 7.9419	LR: 0.010493
Training Epoch: 1 [5440/50000]	Loss: 9.2272	LR: 0.010557
Training Epoch: 1 [5472/50000]	Loss: 11.5940	LR: 0.010621
Training Epoch: 1 [5504/50000]	Loss: 5.0799	LR: 0.010685
Training Epoch: 1 [5536/50000]	Loss: 14.0247	LR: 0.010749
Training Epoch: 1 [5568/50000]	Loss: 8.6821	LR: 0.010813
Training Epoch: 1 [5600/50000]	Loss: 9.8236	LR: 0.010877
Training Epoch: 1 [5632/50000]	Loss: 5.1152	LR: 0.010940
Training Epoch: 1 [5664/50000]	Loss: 4.9023	LR: 0.011004
Training Epoch: 1 [5696/50000]	Loss: 20.8778	LR: 0.011068
Training Epoch: 1 [5728/50000]	Loss: 27.7530	LR: 0.011132
Training Epoch: 1 [5760/50000]	Loss: 4.8042	LR: 0.011196
Training Epoch: 1 [5792/50000]	Loss: 5.5954	LR: 0.011260
Training Epoch: 1 [5824/50000]	Loss: 21.0890	LR: 0.011324
Training Epoch: 1 [5856/50000]	Loss: 5.2275	LR: 0.011388
Training Epoch: 1 [5888/50000]	Loss: 9.0222	LR: 0.011452
Training Epoch: 1 [5920/50000]	Loss: 4.9665	LR: 0.011516
Training Epoch: 1 [5952/50000]	Loss: 9.7088	LR: 0.011580
Training Epoch: 1 [5984/50000]	Loss: 15.7084	LR: 0.011644
Training Epoch: 1 [6016/50000]	Loss: 4.8549	LR: 0.011708
Training Epoch: 1 [6048/50000]	Loss: 4.9856	LR: 0.011772
Training Epoch: 1 [6080/50000]	Loss: 4.6949	LR: 0.011836
Training Epoch: 1 [6112/50000]	Loss: 7.9165	LR: 0.011900
Training Epoch: 1 [6144/50000]	Loss: 9.2093	LR: 0.011964
Training Epoch: 1 [6176/50000]	Loss: 16.8813	LR: 0.012028
Training Epoch: 1 [6208/50000]	Loss: 6.1721	LR: 0.012092
Training Epoch: 1 [6240/50000]	Loss: 4.9712	LR: 0.012156
Training Epoch: 1 [6272/50000]	Loss: 10.2236	LR: 0.012220
Training Epoch: 1 [6304/50000]	Loss: 7.9718	LR: 0.012284
Training Epoch: 1 [6336/50000]	Loss: 6.1892	LR: 0.012348
Training Epoch: 1 [6368/50000]	Loss: 4.8035	LR: 0.012412
Training Epoch: 1 [6400/50000]	Loss: 5.6291	LR: 0.012476
Training Epoch: 1 [6432/50000]	Loss: 6.0642	LR: 0.012540
Training Epoch: 1 [6464/50000]	Loss: 5.1140	LR: 0.012604
Training Epoch: 1 [6496/50000]	Loss: 4.7387	LR: 0.012668
Training Epoch: 1 [6528/50000]	Loss: 5.9186	LR: 0.012732
Training Epoch: 1 [6560/50000]	Loss: 5.4586	LR: 0.012796
Training Epoch: 1 [6592/50000]	Loss: 5.7006	LR: 0.012860
Training Epoch: 1 [6624/50000]	Loss: 5.0359	LR: 0.012924
Training Epoch: 1 [6656/50000]	Loss: 4.8661	LR: 0.012988
Training Epoch: 1 [6688/50000]	Loss: 6.7301	LR: 0.013052
Training Epoch: 1 [6720/50000]	Loss: 12.3284	LR: 0.013116
Training Epoch: 1 [6752/50000]	Loss: 30.1675	LR: 0.013180
Training Epoch: 1 [6784/50000]	Loss: 5.2651	LR: 0.013244
Training Epoch: 1 [6816/50000]	Loss: 4.9116	LR: 0.013308
Training Epoch: 1 [6848/50000]	Loss: 5.4277	LR: 0.013372
Training Epoch: 1 [6880/50000]	Loss: 12.1548	LR: 0.013436
Training Epoch: 1 [6912/50000]	Loss: 5.4002	LR: 0.013500
Training Epoch: 1 [6944/50000]	Loss: 7.2426	LR: 0.013564
Training Epoch: 1 [6976/50000]	Loss: 4.7811	LR: 0.013628
Training Epoch: 1 [7008/50000]	Loss: 8.3175	LR: 0.013692
Training Epoch: 1 [7040/50000]	Loss: 16.9487	LR: 0.013756
Training Epoch: 1 [7072/50000]	Loss: 5.5909	LR: 0.013820
Training Epoch: 1 [7104/50000]	Loss: 9.7735	LR: 0.013884
Training Epoch: 1 [7136/50000]	Loss: 6.9695	LR: 0.013948
Training Epoch: 1 [7168/50000]	Loss: 10.0740	LR: 0.014012
Training Epoch: 1 [7200/50000]	Loss: 16.5446	LR: 0.014075
Training Epoch: 1 [7232/50000]	Loss: 8.7045	LR: 0.014139
Training Epoch: 1 [7264/50000]	Loss: 7.4575	LR: 0.014203
Training Epoch: 1 [7296/50000]	Loss: 6.4652	LR: 0.014267
Training Epoch: 1 [7328/50000]	Loss: 5.3591	LR: 0.014331
Training Epoch: 1 [7360/50000]	Loss: 7.4574	LR: 0.014395
Training Epoch: 1 [7392/50000]	Loss: 5.3196	LR: 0.014459
Training Epoch: 1 [7424/50000]	Loss: 8.4970	LR: 0.014523
Training Epoch: 1 [7456/50000]	Loss: 5.7651	LR: 0.014587
Training Epoch: 1 [7488/50000]	Loss: 5.3959	LR: 0.014651
Training Epoch: 1 [7520/50000]	Loss: 5.5622	LR: 0.014715
Training Epoch: 1 [7552/50000]	Loss: 20.1984	LR: 0.014779
Training Epoch: 1 [7584/50000]	Loss: 5.6146	LR: 0.014843
Training Epoch: 1 [7616/50000]	Loss: 6.3338	LR: 0.014907
Training Epoch: 1 [7648/50000]	Loss: 9.3587	LR: 0.014971
Training Epoch: 1 [7680/50000]	Loss: 5.7694	LR: 0.015035
Training Epoch: 1 [7712/50000]	Loss: 5.8309	LR: 0.015099
Training Epoch: 1 [7744/50000]	Loss: 4.7813	LR: 0.015163
Training Epoch: 1 [7776/50000]	Loss: 53.5005	LR: 0.015227
Training Epoch: 1 [7808/50000]	Loss: 9.7020	LR: 0.015291
Training Epoch: 1 [7840/50000]	Loss: 10.1181	LR: 0.015355
Training Epoch: 1 [7872/50000]	Loss: 5.1625	LR: 0.015419
Training Epoch: 1 [7904/50000]	Loss: 5.6522	LR: 0.015483
Training Epoch: 1 [7936/50000]	Loss: 10.7982	LR: 0.015547
Training Epoch: 1 [7968/50000]	Loss: 18.3715	LR: 0.015611
Training Epoch: 1 [8000/50000]	Loss: 14.6668	LR: 0.015675
Training Epoch: 1 [8032/50000]	Loss: 5.8391	LR: 0.015739
Training Epoch: 1 [8064/50000]	Loss: 5.4404	LR: 0.015803
Training Epoch: 1 [8096/50000]	Loss: 5.6317	LR: 0.015867
Training Epoch: 1 [8128/50000]	Loss: 7.1144	LR: 0.015931
Training Epoch: 1 [8160/50000]	Loss: 7.2685	LR: 0.015995
Training Epoch: 1 [8192/50000]	Loss: 9.9197	LR: 0.016059
Training Epoch: 1 [8224/50000]	Loss: 7.9383	LR: 0.016123
Training Epoch: 1 [8256/50000]	Loss: 5.2440	LR: 0.016187
Training Epoch: 1 [8288/50000]	Loss: 5.6295	LR: 0.016251
Training Epoch: 1 [8320/50000]	Loss: 5.3535	LR: 0.016315
Training Epoch: 1 [8352/50000]	Loss: 5.1904	LR: 0.016379
Training Epoch: 1 [8384/50000]	Loss: 14.3673	LR: 0.016443
Training Epoch: 1 [8416/50000]	Loss: 13.3455	LR: 0.016507
Training Epoch: 1 [8448/50000]	Loss: 6.0494	LR: 0.016571
Training Epoch: 1 [8480/50000]	Loss: 63.0537	LR: 0.016635
Training Epoch: 1 [8512/50000]	Loss: 5.4033	LR: 0.016699
Training Epoch: 1 [8544/50000]	Loss: 7.2727	LR: 0.016763
Training Epoch: 1 [8576/50000]	Loss: 5.2645	LR: 0.016827
Training Epoch: 1 [8608/50000]	Loss: 5.0501	LR: 0.016891
Training Epoch: 1 [8640/50000]	Loss: 5.3174	LR: 0.016955
Training Epoch: 1 [8672/50000]	Loss: 5.2990	LR: 0.017019
Training Epoch: 1 [8704/50000]	Loss: 5.5689	LR: 0.017083
Training Epoch: 1 [8736/50000]	Loss: 5.2139	LR: 0.017147
Training Epoch: 1 [8768/50000]	Loss: 5.0688	LR: 0.017210
Training Epoch: 1 [8800/50000]	Loss: 4.8555	LR: 0.017274
Training Epoch: 1 [8832/50000]	Loss: 5.4480	LR: 0.017338
Training Epoch: 1 [8864/50000]	Loss: 5.2774	LR: 0.017402
Training Epoch: 1 [8896/50000]	Loss: 5.0360	LR: 0.017466
Training Epoch: 1 [8928/50000]	Loss: 7.7034	LR: 0.017530
Training Epoch: 1 [8960/50000]	Loss: 5.9104	LR: 0.017594
Training Epoch: 1 [8992/50000]	Loss: 9.2984	LR: 0.017658
Training Epoch: 1 [9024/50000]	Loss: 5.6778	LR: 0.017722
Training Epoch: 1 [9056/50000]	Loss: 5.0763	LR: 0.017786
Training Epoch: 1 [9088/50000]	Loss: 5.7978	LR: 0.017850
Training Epoch: 1 [9120/50000]	Loss: 5.4970	LR: 0.017914
Training Epoch: 1 [9152/50000]	Loss: 4.6603	LR: 0.017978
Training Epoch: 1 [9184/50000]	Loss: 4.8095	LR: 0.018042
Training Epoch: 1 [9216/50000]	Loss: 5.6254	LR: 0.018106
Training Epoch: 1 [9248/50000]	Loss: 5.1638	LR: 0.018170
Training Epoch: 1 [9280/50000]	Loss: 4.8607	LR: 0.018234
