nohup: ignoring input
Namespace(backbone='resnet50', ft_type='ws', epochs=200, batch_size=32, num_classes=100, warm=1, base=False, lr=0.1, device='cuda:1', num_workers=8, hid_dim=4, n_heads_list=[1])
Files already downloaded and verified
Files already downloaded and verified
Training Epoch: 1 [160/50000]	Loss: 5.6452	LR: 0.000000
Training Epoch: 1 [192/50000]	Loss: 5.9582	LR: 0.000064
Training Epoch: 1 [224/50000]	Loss: 5.0526	LR: 0.000128
Training Epoch: 1 [256/50000]	Loss: 5.3073	LR: 0.000192
Training Epoch: 1 [288/50000]	Loss: 5.1677	LR: 0.000256
Training Epoch: 1 [320/50000]	Loss: 5.0250	LR: 0.000320
Training Epoch: 1 [352/50000]	Loss: 5.2274	LR: 0.000384
Training Epoch: 1 [384/50000]	Loss: 5.1722	LR: 0.000448
Training Epoch: 1 [416/50000]	Loss: 4.9248	LR: 0.000512
Training Epoch: 1 [448/50000]	Loss: 4.9476	LR: 0.000576
Training Epoch: 1 [480/50000]	Loss: 4.9449	LR: 0.000640
Training Epoch: 1 [512/50000]	Loss: 4.7265	LR: 0.000704
Training Epoch: 1 [544/50000]	Loss: 5.4949	LR: 0.000768
Training Epoch: 1 [576/50000]	Loss: 5.2451	LR: 0.000832
Training Epoch: 1 [608/50000]	Loss: 4.9578	LR: 0.000896
Training Epoch: 1 [640/50000]	Loss: 5.4171	LR: 0.000960
Training Epoch: 1 [672/50000]	Loss: 5.2847	LR: 0.001024
Training Epoch: 1 [704/50000]	Loss: 5.4706	LR: 0.001088
Training Epoch: 1 [736/50000]	Loss: 5.1631	LR: 0.001152
Training Epoch: 1 [768/50000]	Loss: 6.1675	LR: 0.001216
Training Epoch: 1 [800/50000]	Loss: 5.5264	LR: 0.001280
Training Epoch: 1 [832/50000]	Loss: 5.6428	LR: 0.001344
Training Epoch: 1 [864/50000]	Loss: 5.3937	LR: 0.001408
Training Epoch: 1 [896/50000]	Loss: 5.4584	LR: 0.001472
Training Epoch: 1 [928/50000]	Loss: 5.0268	LR: 0.001536
Training Epoch: 1 [960/50000]	Loss: 5.0032	LR: 0.001599
Training Epoch: 1 [992/50000]	Loss: 5.4739	LR: 0.001663
Training Epoch: 1 [1024/50000]	Loss: 5.0466	LR: 0.001727
Training Epoch: 1 [1056/50000]	Loss: 5.1456	LR: 0.001791
Training Epoch: 1 [1088/50000]	Loss: 4.7628	LR: 0.001855
Training Epoch: 1 [1120/50000]	Loss: 5.0699	LR: 0.001919
Training Epoch: 1 [1152/50000]	Loss: 5.1716	LR: 0.001983
Training Epoch: 1 [1184/50000]	Loss: 5.0969	LR: 0.002047
Training Epoch: 1 [1216/50000]	Loss: 4.4305	LR: 0.002111
Training Epoch: 1 [1248/50000]	Loss: 5.2515	LR: 0.002175
Training Epoch: 1 [1280/50000]	Loss: 4.8593	LR: 0.002239
Training Epoch: 1 [1312/50000]	Loss: 5.2086	LR: 0.002303
Training Epoch: 1 [1344/50000]	Loss: 5.1070	LR: 0.002367
Training Epoch: 1 [1376/50000]	Loss: 5.0128	LR: 0.002431
Training Epoch: 1 [1408/50000]	Loss: 4.5403	LR: 0.002495
Training Epoch: 1 [1440/50000]	Loss: 4.6506	LR: 0.002559
Training Epoch: 1 [1472/50000]	Loss: 4.7161	LR: 0.002623
Training Epoch: 1 [1504/50000]	Loss: 4.9057	LR: 0.002687
Training Epoch: 1 [1536/50000]	Loss: 4.7274	LR: 0.002751
Training Epoch: 1 [1568/50000]	Loss: 4.6088	LR: 0.002815
Training Epoch: 1 [1600/50000]	Loss: 4.6557	LR: 0.002879
Training Epoch: 1 [1632/50000]	Loss: 4.6110	LR: 0.002943
Training Epoch: 1 [1664/50000]	Loss: 4.6042	LR: 0.003007
Training Epoch: 1 [1696/50000]	Loss: 5.1232	LR: 0.003071
Training Epoch: 1 [1728/50000]	Loss: 4.6906	LR: 0.003135
Training Epoch: 1 [1760/50000]	Loss: 4.6631	LR: 0.003199
Training Epoch: 1 [1792/50000]	Loss: 4.5607	LR: 0.003263
Training Epoch: 1 [1824/50000]	Loss: 4.6989	LR: 0.003327
Training Epoch: 1 [1856/50000]	Loss: 4.5336	LR: 0.003391
Training Epoch: 1 [1888/50000]	Loss: 4.4584	LR: 0.003455
Training Epoch: 1 [1920/50000]	Loss: 4.6332	LR: 0.003519
Training Epoch: 1 [1952/50000]	Loss: 4.9239	LR: 0.003583
Training Epoch: 1 [1984/50000]	Loss: 5.0750	LR: 0.003647
Training Epoch: 1 [2016/50000]	Loss: 4.6217	LR: 0.003711
Training Epoch: 1 [2048/50000]	Loss: 4.5479	LR: 0.003775
Training Epoch: 1 [2080/50000]	Loss: 4.5577	LR: 0.003839
Training Epoch: 1 [2112/50000]	Loss: 4.6723	LR: 0.003903
Training Epoch: 1 [2144/50000]	Loss: 4.7311	LR: 0.003967
Training Epoch: 1 [2176/50000]	Loss: 4.6564	LR: 0.004031
Training Epoch: 1 [2208/50000]	Loss: 4.6143	LR: 0.004095
Training Epoch: 1 [2240/50000]	Loss: 4.6128	LR: 0.004159
Training Epoch: 1 [2272/50000]	Loss: 4.5877	LR: 0.004223
Training Epoch: 1 [2304/50000]	Loss: 4.6162	LR: 0.004287
Training Epoch: 1 [2336/50000]	Loss: 4.5514	LR: 0.004351
Training Epoch: 1 [2368/50000]	Loss: 4.6113	LR: 0.004415
Training Epoch: 1 [2400/50000]	Loss: 4.6102	LR: 0.004479
Training Epoch: 1 [2432/50000]	Loss: 4.6046	LR: 0.004543
Training Epoch: 1 [2464/50000]	Loss: 4.5530	LR: 0.004607
Training Epoch: 1 [2496/50000]	Loss: 4.5889	LR: 0.004671
Training Epoch: 1 [2528/50000]	Loss: 4.6142	LR: 0.004734
Training Epoch: 1 [2560/50000]	Loss: 4.6324	LR: 0.004798
Training Epoch: 1 [2592/50000]	Loss: 4.5517	LR: 0.004862
Training Epoch: 1 [2624/50000]	Loss: 4.5985	LR: 0.004926
Training Epoch: 1 [2656/50000]	Loss: 4.5423	LR: 0.004990
Training Epoch: 1 [2688/50000]	Loss: 4.6452	LR: 0.005054
Training Epoch: 1 [2720/50000]	Loss: 4.5564	LR: 0.005118
Training Epoch: 1 [2752/50000]	Loss: 4.6234	LR: 0.005182
Training Epoch: 1 [2784/50000]	Loss: 4.6168	LR: 0.005246
Training Epoch: 1 [2816/50000]	Loss: 4.4965	LR: 0.005310
Training Epoch: 1 [2848/50000]	Loss: 4.5537	LR: 0.005374
Training Epoch: 1 [2880/50000]	Loss: 4.5498	LR: 0.005438
Training Epoch: 1 [2912/50000]	Loss: 4.6031	LR: 0.005502
Training Epoch: 1 [2944/50000]	Loss: 4.5273	LR: 0.005566
Training Epoch: 1 [2976/50000]	Loss: 4.5642	LR: 0.005630
Training Epoch: 1 [3008/50000]	Loss: 4.5171	LR: 0.005694
Training Epoch: 1 [3040/50000]	Loss: 4.5284	LR: 0.005758
Training Epoch: 1 [3072/50000]	Loss: 4.5052	LR: 0.005822
Training Epoch: 1 [3104/50000]	Loss: 4.6607	LR: 0.005886
Training Epoch: 1 [3136/50000]	Loss: 4.4776	LR: 0.005950
Training Epoch: 1 [3168/50000]	Loss: 4.6193	LR: 0.006014
Training Epoch: 1 [3200/50000]	Loss: 4.5914	LR: 0.006078
Training Epoch: 1 [3232/50000]	Loss: 4.6973	LR: 0.006142
Training Epoch: 1 [3264/50000]	Loss: 4.6238	LR: 0.006206
Training Epoch: 1 [3296/50000]	Loss: 4.6069	LR: 0.006270
Training Epoch: 1 [3328/50000]	Loss: 4.6059	LR: 0.006334
Training Epoch: 1 [3360/50000]	Loss: 4.5953	LR: 0.006398
Training Epoch: 1 [3392/50000]	Loss: 4.5666	LR: 0.006462
Training Epoch: 1 [3424/50000]	Loss: 4.5430	LR: 0.006526
Training Epoch: 1 [3456/50000]	Loss: 4.4636	LR: 0.006590
Training Epoch: 1 [3488/50000]	Loss: 4.8790	LR: 0.006654
Training Epoch: 1 [3520/50000]	Loss: 4.7118	LR: 0.006718
Training Epoch: 1 [3552/50000]	Loss: 4.5741	LR: 0.006782
Training Epoch: 1 [3584/50000]	Loss: 4.6187	LR: 0.006846
Training Epoch: 1 [3616/50000]	Loss: 4.5822	LR: 0.006910
Training Epoch: 1 [3648/50000]	Loss: 4.6138	LR: 0.006974
Training Epoch: 1 [3680/50000]	Loss: 4.5996	LR: 0.007038
Training Epoch: 1 [3712/50000]	Loss: 4.5833	LR: 0.007102
Training Epoch: 1 [3744/50000]	Loss: 4.5840	LR: 0.007166
Training Epoch: 1 [3776/50000]	Loss: 4.6787	LR: 0.007230
Training Epoch: 1 [3808/50000]	Loss: 4.5785	LR: 0.007294
Training Epoch: 1 [3840/50000]	Loss: 4.6392	LR: 0.007358
Training Epoch: 1 [3872/50000]	Loss: 4.5456	LR: 0.007422
Training Epoch: 1 [3904/50000]	Loss: 4.6090	LR: 0.007486
Training Epoch: 1 [3936/50000]	Loss: 4.5957	LR: 0.007550
Training Epoch: 1 [3968/50000]	Loss: 4.6109	LR: 0.007614
Training Epoch: 1 [4000/50000]	Loss: 4.5724	LR: 0.007678
Training Epoch: 1 [4032/50000]	Loss: 4.5850	LR: 0.007742
Training Epoch: 1 [4064/50000]	Loss: 4.6180	LR: 0.007806
Training Epoch: 1 [4096/50000]	Loss: 4.6356	LR: 0.007869
Training Epoch: 1 [4128/50000]	Loss: 4.5824	LR: 0.007933
Training Epoch: 1 [4160/50000]	Loss: 4.5857	LR: 0.007997
Training Epoch: 1 [4192/50000]	Loss: 4.5468	LR: 0.008061
Training Epoch: 1 [4224/50000]	Loss: 4.6041	LR: 0.008125
Training Epoch: 1 [4256/50000]	Loss: 4.5960	LR: 0.008189
Training Epoch: 1 [4288/50000]	Loss: 4.5473	LR: 0.008253
Training Epoch: 1 [4320/50000]	Loss: 4.4794	LR: 0.008317
Training Epoch: 1 [4352/50000]	Loss: 4.3662	LR: 0.008381
Training Epoch: 1 [4384/50000]	Loss: 4.6026	LR: 0.008445
Training Epoch: 1 [4416/50000]	Loss: 4.8061	LR: 0.008509
Training Epoch: 1 [4448/50000]	Loss: 4.5654	LR: 0.008573
Training Epoch: 1 [4480/50000]	Loss: 4.5459	LR: 0.008637
Training Epoch: 1 [4512/50000]	Loss: 4.5431	LR: 0.008701
Training Epoch: 1 [4544/50000]	Loss: 4.5559	LR: 0.008765
Training Epoch: 1 [4576/50000]	Loss: 4.5300	LR: 0.008829
Training Epoch: 1 [4608/50000]	Loss: 4.5426	LR: 0.008893
Training Epoch: 1 [4640/50000]	Loss: 4.6059	LR: 0.008957
Training Epoch: 1 [4672/50000]	Loss: 4.5498	LR: 0.009021
Training Epoch: 1 [4704/50000]	Loss: 4.4466	LR: 0.009085
Training Epoch: 1 [4736/50000]	Loss: 4.6375	LR: 0.009149
Training Epoch: 1 [4768/50000]	Loss: 4.6148	LR: 0.009213
Training Epoch: 1 [4800/50000]	Loss: 4.6483	LR: 0.009277
Training Epoch: 1 [4832/50000]	Loss: 4.6184	LR: 0.009341
Training Epoch: 1 [4864/50000]	Loss: 4.8360	LR: 0.009405
Training Epoch: 1 [4896/50000]	Loss: 4.7580	LR: 0.009469
Training Epoch: 1 [4928/50000]	Loss: 4.7597	LR: 0.009533
Training Epoch: 1 [4960/50000]	Loss: 4.5932	LR: 0.009597
Training Epoch: 1 [4992/50000]	Loss: 4.7397	LR: 0.009661
Training Epoch: 1 [5024/50000]	Loss: 4.8965	LR: 0.009725
Training Epoch: 1 [5056/50000]	Loss: 4.7734	LR: 0.009789
Training Epoch: 1 [5088/50000]	Loss: 4.7073	LR: 0.009853
Training Epoch: 1 [5120/50000]	Loss: 4.6089	LR: 0.009917
Training Epoch: 1 [5152/50000]	Loss: 4.6118	LR: 0.009981
Training Epoch: 1 [5184/50000]	Loss: 4.6178	LR: 0.010045
Training Epoch: 1 [5216/50000]	Loss: 4.6540	LR: 0.010109
Training Epoch: 1 [5248/50000]	Loss: 4.6420	LR: 0.010173
Training Epoch: 1 [5280/50000]	Loss: 4.5713	LR: 0.010237
Training Epoch: 1 [5312/50000]	Loss: 4.6151	LR: 0.010301
Training Epoch: 1 [5344/50000]	Loss: 4.7256	LR: 0.010365
Training Epoch: 1 [5376/50000]	Loss: 4.6524	LR: 0.010429
Training Epoch: 1 [5408/50000]	Loss: 4.6845	LR: 0.010493
Training Epoch: 1 [5440/50000]	Loss: 4.5495	LR: 0.010557
Training Epoch: 1 [5472/50000]	Loss: 4.5791	LR: 0.010621
Training Epoch: 1 [5504/50000]	Loss: 4.6004	LR: 0.010685
Training Epoch: 1 [5536/50000]	Loss: 4.6007	LR: 0.010749
Training Epoch: 1 [5568/50000]	Loss: 4.5989	LR: 0.010813
Training Epoch: 1 [5600/50000]	Loss: 4.5983	LR: 0.010877
Training Epoch: 1 [5632/50000]	Loss: 4.6141	LR: 0.010940
Training Epoch: 1 [5664/50000]	Loss: 4.6437	LR: 0.011004
Training Epoch: 1 [5696/50000]	Loss: 4.5966	LR: 0.011068
Training Epoch: 1 [5728/50000]	Loss: 4.6047	LR: 0.011132
Training Epoch: 1 [5760/50000]	Loss: 4.6145	LR: 0.011196
Training Epoch: 1 [5792/50000]	Loss: 4.6172	LR: 0.011260
Training Epoch: 1 [5824/50000]	Loss: 4.5982	LR: 0.011324
Training Epoch: 1 [5856/50000]	Loss: 4.6092	LR: 0.011388
Training Epoch: 1 [5888/50000]	Loss: 4.5992	LR: 0.011452
Training Epoch: 1 [5920/50000]	Loss: 4.6073	LR: 0.011516
Training Epoch: 1 [5952/50000]	Loss: 4.6162	LR: 0.011580
Training Epoch: 1 [5984/50000]	Loss: 4.6438	LR: 0.011644
Training Epoch: 1 [6016/50000]	Loss: 4.7908	LR: 0.011708
Training Epoch: 1 [6048/50000]	Loss: 4.6057	LR: 0.011772
Training Epoch: 1 [6080/50000]	Loss: 4.6137	LR: 0.011836
Training Epoch: 1 [6112/50000]	Loss: 4.6952	LR: 0.011900
Training Epoch: 1 [6144/50000]	Loss: 4.7129	LR: 0.011964
Training Epoch: 1 [6176/50000]	Loss: 4.6792	LR: 0.012028
Training Epoch: 1 [6208/50000]	Loss: 4.6158	LR: 0.012092
Training Epoch: 1 [6240/50000]	Loss: 4.6312	LR: 0.012156
Training Epoch: 1 [6272/50000]	Loss: 4.6633	LR: 0.012220
Training Epoch: 1 [6304/50000]	Loss: 4.7462	LR: 0.012284
Training Epoch: 1 [6336/50000]	Loss: 4.6087	LR: 0.012348
Training Epoch: 1 [6368/50000]	Loss: 4.6324	LR: 0.012412
Training Epoch: 1 [6400/50000]	Loss: 4.6031	LR: 0.012476
Training Epoch: 1 [6432/50000]	Loss: 4.6735	LR: 0.012540
Training Epoch: 1 [6464/50000]	Loss: 4.7057	LR: 0.012604
Training Epoch: 1 [6496/50000]	Loss: 4.5720	LR: 0.012668
Training Epoch: 1 [6528/50000]	Loss: 4.5868	LR: 0.012732
Training Epoch: 1 [6560/50000]	Loss: 4.5916	LR: 0.012796
Training Epoch: 1 [6592/50000]	Loss: 4.6118	LR: 0.012860
Training Epoch: 1 [6624/50000]	Loss: 4.6068	LR: 0.012924
Training Epoch: 1 [6656/50000]	Loss: 4.6253	LR: 0.012988
Training Epoch: 1 [6688/50000]	Loss: 4.6674	LR: 0.013052
Training Epoch: 1 [6720/50000]	Loss: 4.6329	LR: 0.013116
Training Epoch: 1 [6752/50000]	Loss: 4.6993	LR: 0.013180
Training Epoch: 1 [6784/50000]	Loss: 4.6435	LR: 0.013244
Training Epoch: 1 [6816/50000]	Loss: 4.6216	LR: 0.013308
Training Epoch: 1 [6848/50000]	Loss: 4.6013	LR: 0.013372
Training Epoch: 1 [6880/50000]	Loss: 4.5441	LR: 0.013436
Training Epoch: 1 [6912/50000]	Loss: 4.6547	LR: 0.013500
Training Epoch: 1 [6944/50000]	Loss: 4.5880	LR: 0.013564
Training Epoch: 1 [6976/50000]	Loss: 4.4821	LR: 0.013628
Training Epoch: 1 [7008/50000]	Loss: 4.6870	LR: 0.013692
Training Epoch: 1 [7040/50000]	Loss: 4.7509	LR: 0.013756
Training Epoch: 1 [7072/50000]	Loss: 4.5140	LR: 0.013820
Training Epoch: 1 [7104/50000]	Loss: 4.6490	LR: 0.013884
Training Epoch: 1 [7136/50000]	Loss: 4.6219	LR: 0.013948
Training Epoch: 1 [7168/50000]	Loss: 4.6123	LR: 0.014012
Training Epoch: 1 [7200/50000]	Loss: 4.6167	LR: 0.014075
Training Epoch: 1 [7232/50000]	Loss: 4.6832	LR: 0.014139
Training Epoch: 1 [7264/50000]	Loss: 4.6898	LR: 0.014203
Training Epoch: 1 [7296/50000]	Loss: 4.6167	LR: 0.014267
Training Epoch: 1 [7328/50000]	Loss: 4.6247	LR: 0.014331
Training Epoch: 1 [7360/50000]	Loss: 4.6180	LR: 0.014395
Training Epoch: 1 [7392/50000]	Loss: 4.6767	LR: 0.014459
Training Epoch: 1 [7424/50000]	Loss: 4.5011	LR: 0.014523
Training Epoch: 1 [7456/50000]	Loss: 4.6895	LR: 0.014587
Training Epoch: 1 [7488/50000]	Loss: 4.5707	LR: 0.014651
Training Epoch: 1 [7520/50000]	Loss: 4.6041	LR: 0.014715
Training Epoch: 1 [7552/50000]	Loss: 4.6388	LR: 0.014779
Training Epoch: 1 [7584/50000]	Loss: 4.6198	LR: 0.014843
Training Epoch: 1 [7616/50000]	Loss: 4.5509	LR: 0.014907
Training Epoch: 1 [7648/50000]	Loss: 4.7552	LR: 0.014971
Training Epoch: 1 [7680/50000]	Loss: 4.6493	LR: 0.015035
Training Epoch: 1 [7712/50000]	Loss: 4.6767	LR: 0.015099
Training Epoch: 1 [7744/50000]	Loss: 4.6330	LR: 0.015163
Training Epoch: 1 [7776/50000]	Loss: 4.6017	LR: 0.015227
Training Epoch: 1 [7808/50000]	Loss: 4.5982	LR: 0.015291
Training Epoch: 1 [7840/50000]	Loss: 4.5840	LR: 0.015355
Training Epoch: 1 [7872/50000]	Loss: 4.5588	LR: 0.015419
Training Epoch: 1 [7904/50000]	Loss: 4.8886	LR: 0.015483
Training Epoch: 1 [7936/50000]	Loss: 4.7570	LR: 0.015547
Training Epoch: 1 [7968/50000]	Loss: 4.6713	LR: 0.015611
Training Epoch: 1 [8000/50000]	Loss: 4.8994	LR: 0.015675
Training Epoch: 1 [8032/50000]	Loss: 4.5011	LR: 0.015739
Training Epoch: 1 [8064/50000]	Loss: 4.5179	LR: 0.015803
Training Epoch: 1 [8096/50000]	Loss: 4.4776	LR: 0.015867
Training Epoch: 1 [8128/50000]	Loss: 4.4707	LR: 0.015931
Training Epoch: 1 [8160/50000]	Loss: 4.8047	LR: 0.015995
Training Epoch: 1 [8192/50000]	Loss: 4.7671	LR: 0.016059
Training Epoch: 1 [8224/50000]	Loss: 4.7015	LR: 0.016123
Training Epoch: 1 [8256/50000]	Loss: 4.6211	LR: 0.016187
Training Epoch: 1 [8288/50000]	Loss: 4.9599	LR: 0.016251
Training Epoch: 1 [8320/50000]	Loss: 4.8693	LR: 0.016315
Training Epoch: 1 [8352/50000]	Loss: 4.7977	LR: 0.016379
Training Epoch: 1 [8384/50000]	Loss: 4.6627	LR: 0.016443
Training Epoch: 1 [8416/50000]	Loss: 4.6377	LR: 0.016507
Training Epoch: 1 [8448/50000]	Loss: 4.5995	LR: 0.016571
Training Epoch: 1 [8480/50000]	Loss: 4.6191	LR: 0.016635
Training Epoch: 1 [8512/50000]	Loss: 4.6962	LR: 0.016699
Training Epoch: 1 [8544/50000]	Loss: 4.6541	LR: 0.016763
Training Epoch: 1 [8576/50000]	Loss: 4.6123	LR: 0.016827
Training Epoch: 1 [8608/50000]	Loss: 4.6450	LR: 0.016891
Training Epoch: 1 [8640/50000]	Loss: 4.5999	LR: 0.016955
Training Epoch: 1 [8672/50000]	Loss: 4.6242	LR: 0.017019
Training Epoch: 1 [8704/50000]	Loss: 4.5959	LR: 0.017083
Training Epoch: 1 [8736/50000]	Loss: 4.5295	LR: 0.017147
Training Epoch: 1 [8768/50000]	Loss: 4.6376	LR: 0.017210
Training Epoch: 1 [8800/50000]	Loss: 4.6780	LR: 0.017274
Training Epoch: 1 [8832/50000]	Loss: 4.5894	LR: 0.017338
Training Epoch: 1 [8864/50000]	Loss: 4.6579	LR: 0.017402
Training Epoch: 1 [8896/50000]	Loss: 4.7006	LR: 0.017466
Training Epoch: 1 [8928/50000]	Loss: 4.6665	LR: 0.017530
Training Epoch: 1 [8960/50000]	Loss: 4.6079	LR: 0.017594
Training Epoch: 1 [8992/50000]	Loss: 4.5665	LR: 0.017658
Training Epoch: 1 [9024/50000]	Loss: 4.5754	LR: 0.017722
Training Epoch: 1 [9056/50000]	Loss: 4.5150	LR: 0.017786
Training Epoch: 1 [9088/50000]	Loss: 4.6444	LR: 0.017850
Training Epoch: 1 [9120/50000]	Loss: 4.7934	LR: 0.017914
Training Epoch: 1 [9152/50000]	Loss: 4.6978	LR: 0.017978
Training Epoch: 1 [9184/50000]	Loss: 4.5521	LR: 0.018042
Training Epoch: 1 [9216/50000]	Loss: 4.6250	LR: 0.018106
Training Epoch: 1 [9248/50000]	Loss: 4.6797	LR: 0.018170
Training Epoch: 1 [9280/50000]	Loss: 4.6046	LR: 0.018234
Training Epoch: 1 [9312/50000]	Loss: 4.6385	LR: 0.018298
Training Epoch: 1 [9344/50000]	Loss: 4.6255	LR: 0.018362
Training Epoch: 1 [9376/50000]	Loss: 4.4393	LR: 0.018426
Training Epoch: 1 [9408/50000]	Loss: 4.9477	LR: 0.018490
Training Epoch: 1 [9440/50000]	Loss: 4.6597	LR: 0.018554
Training Epoch: 1 [9472/50000]	Loss: 4.6154	LR: 0.018618
Training Epoch: 1 [9504/50000]	Loss: 4.6503	LR: 0.018682
Training Epoch: 1 [9536/50000]	Loss: 4.6156	LR: 0.018746
Training Epoch: 1 [9568/50000]	Loss: 4.6284	LR: 0.018810
Training Epoch: 1 [9600/50000]	Loss: 4.6014	LR: 0.018874
Training Epoch: 1 [9632/50000]	Loss: 4.6015	LR: 0.018938
Training Epoch: 1 [9664/50000]	Loss: 4.6214	LR: 0.019002
Training Epoch: 1 [9696/50000]	Loss: 4.5889	LR: 0.019066
Training Epoch: 1 [9728/50000]	Loss: 4.6164	LR: 0.019130
Training Epoch: 1 [9760/50000]	Loss: 4.6069	LR: 0.019194
Training Epoch: 1 [9792/50000]	Loss: 4.7343	LR: 0.019258
Training Epoch: 1 [9824/50000]	Loss: 4.5984	LR: 0.019322
Training Epoch: 1 [9856/50000]	Loss: 4.6086	LR: 0.019386
Training Epoch: 1 [9888/50000]	Loss: 4.6113	LR: 0.019450
Training Epoch: 1 [9920/50000]	Loss: 4.5980	LR: 0.019514
Training Epoch: 1 [9952/50000]	Loss: 4.6163	LR: 0.019578
Training Epoch: 1 [9984/50000]	Loss: 4.6205	LR: 0.019642
Training Epoch: 1 [10016/50000]	Loss: 4.6462	LR: 0.019706
Training Epoch: 1 [10048/50000]	Loss: 4.5871	LR: 0.019770
Training Epoch: 1 [10080/50000]	Loss: 4.5802	LR: 0.019834
Training Epoch: 1 [10112/50000]	Loss: 4.5393	LR: 0.019898
Training Epoch: 1 [10144/50000]	Loss: 4.7265	LR: 0.019962
Training Epoch: 1 [10176/50000]	Loss: 4.5861	LR: 0.020026
Training Epoch: 1 [10208/50000]	Loss: 4.6376	LR: 0.020090
Training Epoch: 1 [10240/50000]	Loss: 4.6125	LR: 0.020154
Training Epoch: 1 [10272/50000]	Loss: 4.6354	LR: 0.020218
Training Epoch: 1 [10304/50000]	Loss: 4.6154	LR: 0.020282
Training Epoch: 1 [10336/50000]	Loss: 4.6513	LR: 0.020345
Training Epoch: 1 [10368/50000]	Loss: 4.6081	LR: 0.020409
Training Epoch: 1 [10400/50000]	Loss: 4.6166	LR: 0.020473
Training Epoch: 1 [10432/50000]	Loss: 4.4919	LR: 0.020537
Training Epoch: 1 [10464/50000]	Loss: 4.7083	LR: 0.020601
Training Epoch: 1 [10496/50000]	Loss: 4.6188	LR: 0.020665
Training Epoch: 1 [10528/50000]	Loss: 4.6078	LR: 0.020729
Training Epoch: 1 [10560/50000]	Loss: 4.5707	LR: 0.020793
Training Epoch: 1 [10592/50000]	Loss: 4.5980	LR: 0.020857
Training Epoch: 1 [10624/50000]	Loss: 4.5903	LR: 0.020921
Training Epoch: 1 [10656/50000]	Loss: 4.5716	LR: 0.020985
Training Epoch: 1 [10688/50000]	Loss: 4.5208	LR: 0.021049
Training Epoch: 1 [10720/50000]	Loss: 4.6526	LR: 0.021113
Training Epoch: 1 [10752/50000]	Loss: 4.6862	LR: 0.021177
Training Epoch: 1 [10784/50000]	Loss: 4.6897	LR: 0.021241
Training Epoch: 1 [10816/50000]	Loss: 4.5876	LR: 0.021305
Training Epoch: 1 [10848/50000]	Loss: 4.5355	LR: 0.021369
Training Epoch: 1 [10880/50000]	Loss: 4.6092	LR: 0.021433
Training Epoch: 1 [10912/50000]	Loss: 4.6096	LR: 0.021497
Training Epoch: 1 [10944/50000]	Loss: 4.5920	LR: 0.021561
Training Epoch: 1 [10976/50000]	Loss: 4.5650	LR: 0.021625
Training Epoch: 1 [11008/50000]	Loss: 4.4894	LR: 0.021689
Training Epoch: 1 [11040/50000]	Loss: 4.3032	LR: 0.021753
Training Epoch: 1 [11072/50000]	Loss: 4.5311	LR: 0.021817
Training Epoch: 1 [11104/50000]	Loss: 4.7833	LR: 0.021881
Training Epoch: 1 [11136/50000]	Loss: 4.9040	LR: 0.021945
Training Epoch: 1 [11168/50000]	Loss: 4.4817	LR: 0.022009
Training Epoch: 1 [11200/50000]	Loss: 4.5577	LR: 0.022073
Training Epoch: 1 [11232/50000]	Loss: 4.6418	LR: 0.022137
Training Epoch: 1 [11264/50000]	Loss: 4.6110	LR: 0.022201
Training Epoch: 1 [11296/50000]	Loss: 4.6980	LR: 0.022265
Training Epoch: 1 [11328/50000]	Loss: 4.6726	LR: 0.022329
Training Epoch: 1 [11360/50000]	Loss: 4.5175	LR: 0.022393
Training Epoch: 1 [11392/50000]	Loss: 4.6684	LR: 0.022457
Training Epoch: 1 [11424/50000]	Loss: 5.2009	LR: 0.022521
Training Epoch: 1 [11456/50000]	Loss: 4.7451	LR: 0.022585
Training Epoch: 1 [11488/50000]	Loss: 4.6215	LR: 0.022649
Training Epoch: 1 [11520/50000]	Loss: 4.6313	LR: 0.022713
Training Epoch: 1 [11552/50000]	Loss: 4.7252	LR: 0.022777
Training Epoch: 1 [11584/50000]	Loss: 4.8615	LR: 0.022841
Training Epoch: 1 [11616/50000]	Loss: 4.7446	LR: 0.022905
Training Epoch: 1 [11648/50000]	Loss: 4.6224	LR: 0.022969
Training Epoch: 1 [11680/50000]	Loss: 4.5910	LR: 0.023033
Training Epoch: 1 [11712/50000]	Loss: 4.7010	LR: 0.023097
Training Epoch: 1 [11744/50000]	Loss: 4.9048	LR: 0.023161
Training Epoch: 1 [11776/50000]	Loss: 4.6246	LR: 0.023225
Training Epoch: 1 [11808/50000]	Loss: 4.6681	LR: 0.023289
Training Epoch: 1 [11840/50000]	Loss: 4.6793	LR: 0.023353
Training Epoch: 1 [11872/50000]	Loss: 4.6725	LR: 0.023417
Training Epoch: 1 [11904/50000]	Loss: 4.7795	LR: 0.023480
Training Epoch: 1 [11936/50000]	Loss: 4.6998	LR: 0.023544
Training Epoch: 1 [11968/50000]	Loss: 4.6389	LR: 0.023608
Training Epoch: 1 [12000/50000]	Loss: 4.6020	LR: 0.023672
Training Epoch: 1 [12032/50000]	Loss: 4.6212	LR: 0.023736
Training Epoch: 1 [12064/50000]	Loss: 4.6549	LR: 0.023800
Training Epoch: 1 [12096/50000]	Loss: 4.6567	LR: 0.023864
Training Epoch: 1 [12128/50000]	Loss: 4.7384	LR: 0.023928
Training Epoch: 1 [12160/50000]	Loss: 4.7211	LR: 0.023992
Training Epoch: 1 [12192/50000]	Loss: 4.6098	LR: 0.024056
Training Epoch: 1 [12224/50000]	Loss: 4.5910	LR: 0.024120
Training Epoch: 1 [12256/50000]	Loss: 4.6697	LR: 0.024184
Training Epoch: 1 [12288/50000]	Loss: 4.7379	LR: 0.024248
Training Epoch: 1 [12320/50000]	Loss: 4.6757	LR: 0.024312
Training Epoch: 1 [12352/50000]	Loss: 4.6400	LR: 0.024376
Training Epoch: 1 [12384/50000]	Loss: 4.6300	LR: 0.024440
Training Epoch: 1 [12416/50000]	Loss: 4.4884	LR: 0.024504
Training Epoch: 1 [12448/50000]	Loss: 4.5535	LR: 0.024568
Training Epoch: 1 [12480/50000]	Loss: 4.7788	LR: 0.024632
Training Epoch: 1 [12512/50000]	Loss: 4.6786	LR: 0.024696
Training Epoch: 1 [12544/50000]	Loss: 4.6705	LR: 0.024760
Training Epoch: 1 [12576/50000]	Loss: 4.7206	LR: 0.024824
Training Epoch: 1 [12608/50000]	Loss: 4.6520	LR: 0.024888
Training Epoch: 1 [12640/50000]	Loss: 4.6002	LR: 0.024952
Training Epoch: 1 [12672/50000]	Loss: 4.7096	LR: 0.025016
Training Epoch: 1 [12704/50000]	Loss: 4.6704	LR: 0.025080
Training Epoch: 1 [12736/50000]	Loss: 5.1828	LR: 0.025144
Training Epoch: 1 [12768/50000]	Loss: 4.8311	LR: 0.025208
Training Epoch: 1 [12800/50000]	Loss: 4.6885	LR: 0.025272
Training Epoch: 1 [12832/50000]	Loss: 4.6065	LR: 0.025336
Training Epoch: 1 [12864/50000]	Loss: 4.6869	LR: 0.025400
Training Epoch: 1 [12896/50000]	Loss: 4.5909	LR: 0.025464
Training Epoch: 1 [12928/50000]	Loss: 4.5401	LR: 0.025528
Training Epoch: 1 [12960/50000]	Loss: 4.7849	LR: 0.025592
Training Epoch: 1 [12992/50000]	Loss: 4.5828	LR: 0.025656
Training Epoch: 1 [13024/50000]	Loss: 4.6763	LR: 0.025720
Training Epoch: 1 [13056/50000]	Loss: 4.6394	LR: 0.025784
Training Epoch: 1 [13088/50000]	Loss: 4.6309	LR: 0.025848
Training Epoch: 1 [13120/50000]	Loss: 4.5577	LR: 0.025912
Training Epoch: 1 [13152/50000]	Loss: 4.7118	LR: 0.025976
Training Epoch: 1 [13184/50000]	Loss: 4.4904	LR: 0.026040
Training Epoch: 1 [13216/50000]	Loss: 4.6171	LR: 0.026104
Training Epoch: 1 [13248/50000]	Loss: 4.7358	LR: 0.026168
Training Epoch: 1 [13280/50000]	Loss: 4.6126	LR: 0.026232
Training Epoch: 1 [13312/50000]	Loss: 4.5646	LR: 0.026296
Training Epoch: 1 [13344/50000]	Loss: 4.5342	LR: 0.026360
Training Epoch: 1 [13376/50000]	Loss: 4.6234	LR: 0.026424
Training Epoch: 1 [13408/50000]	Loss: 4.6488	LR: 0.026488
Training Epoch: 1 [13440/50000]	Loss: 4.8996	LR: 0.026552
Training Epoch: 1 [13472/50000]	Loss: 4.6505	LR: 0.026615
Training Epoch: 1 [13504/50000]	Loss: 4.5978	LR: 0.026679
Training Epoch: 1 [13536/50000]	Loss: 4.6553	LR: 0.026743
Training Epoch: 1 [13568/50000]	Loss: 4.5604	LR: 0.026807
Training Epoch: 1 [13600/50000]	Loss: 4.7774	LR: 0.026871
Training Epoch: 1 [13632/50000]	Loss: 4.5891	LR: 0.026935
Training Epoch: 1 [13664/50000]	Loss: 4.6770	LR: 0.026999
Training Epoch: 1 [13696/50000]	Loss: 4.6434	LR: 0.027063
Training Epoch: 1 [13728/50000]	Loss: 4.6246	LR: 0.027127
Training Epoch: 1 [13760/50000]	Loss: 4.5213	LR: 0.027191
Training Epoch: 1 [13792/50000]	Loss: 4.8374	LR: 0.027255
Training Epoch: 1 [13824/50000]	Loss: 4.7998	LR: 0.027319
